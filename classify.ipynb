{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyts.image import GramianAngularField\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "import keras\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\program files\\Anaconda3\\lib\\site-packages\\numba\\np\\ufunc\\parallel.py:355: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 11004. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 28, 28)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(300, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#transfer signals into 2D images\n",
    "path = \"D:\\\\APE\\\\ml_model\\\\train_data\\\\\" \n",
    "files= os.listdir(path) \n",
    "train_label = [] \n",
    "train_signal = [] #700 seq\n",
    "length = []\n",
    "gasf = GramianAngularField(image_size=28, method='summation')\n",
    "for file in files: \n",
    "    data = np.loadtxt(open(path+file),delimiter=\",\",skiprows=0)\n",
    "    seq_len = len(data) - 1\n",
    "    length.append(seq_len)\n",
    "    train_label.append(data[-1])\n",
    "    X = data[0:seq_len]\n",
    "    X = X.reshape(1, -1)\n",
    "    X_gasf = gasf.fit_transform(X)\n",
    "    train_signal.append(X_gasf[0])\n",
    "\n",
    "\n",
    "train_sig = np.array(train_signal)\n",
    "train_lab = np.array(train_label)\n",
    "print(train_sig.shape)\n",
    "\n",
    "path = \"D:\\\\APE\\\\ml_model\\\\test_data\\\\\" \n",
    "files= os.listdir(path) \n",
    "test_label = []\n",
    "test_signal = [] #300 seq\n",
    "length = []\n",
    "for file in files: \n",
    "    data = np.loadtxt(open(path+file),delimiter=\",\",skiprows=0)\n",
    "    seq_len = len(data) - 1\n",
    "    length.append(seq_len)\n",
    "    test_label.append(data[-1])\n",
    "    X = data[0:seq_len]\n",
    "    X = X.reshape(1, -1)\n",
    "    X_gasf = gasf.fit_transform(X)\n",
    "    test_signal.append(X_gasf[0])\n",
    "    \n",
    "test_sig = np.array(test_signal)\n",
    "test_lab = np.array(test_label)\n",
    "print(test_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - ETA: 58s - loss: 0.6883 - accuracy: 0.406 - ETA: 29s - loss: 0.9112 - accuracy: 0.453 - ETA: 19s - loss: 0.8376 - accuracy: 0.468 - ETA: 14s - loss: 0.7826 - accuracy: 0.523 - ETA: 11s - loss: 0.7777 - accuracy: 0.537 - ETA: 9s - loss: 0.7823 - accuracy: 0.520 - ETA: 7s - loss: 0.7692 - accuracy: 0.50 - ETA: 6s - loss: 0.7701 - accuracy: 0.49 - ETA: 5s - loss: 0.7654 - accuracy: 0.49 - ETA: 4s - loss: 0.7612 - accuracy: 0.50 - ETA: 4s - loss: 0.7541 - accuracy: 0.49 - ETA: 3s - loss: 0.7492 - accuracy: 0.49 - ETA: 3s - loss: 0.7426 - accuracy: 0.50 - ETA: 2s - loss: 0.7395 - accuracy: 0.50 - ETA: 2s - loss: 0.7340 - accuracy: 0.51 - ETA: 1s - loss: 0.7314 - accuracy: 0.51 - ETA: 1s - loss: 0.7295 - accuracy: 0.51 - ETA: 1s - loss: 0.7290 - accuracy: 0.50 - ETA: 0s - loss: 0.7263 - accuracy: 0.50 - ETA: 0s - loss: 0.7245 - accuracy: 0.50 - ETA: 0s - loss: 0.7263 - accuracy: 0.50 - 7s 10ms/sample - loss: 0.7251 - accuracy: 0.5043 - val_loss: 0.7177 - val_accuracy: 0.5533\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - ETA: 3s - loss: 0.7290 - accuracy: 0.68 - ETA: 3s - loss: 0.7079 - accuracy: 0.57 - ETA: 2s - loss: 0.6984 - accuracy: 0.56 - ETA: 2s - loss: 0.6918 - accuracy: 0.57 - ETA: 2s - loss: 0.6913 - accuracy: 0.56 - ETA: 2s - loss: 0.6881 - accuracy: 0.56 - ETA: 2s - loss: 0.6910 - accuracy: 0.54 - ETA: 2s - loss: 0.6943 - accuracy: 0.53 - ETA: 2s - loss: 0.6928 - accuracy: 0.52 - ETA: 1s - loss: 0.6902 - accuracy: 0.52 - ETA: 1s - loss: 0.6892 - accuracy: 0.51 - ETA: 1s - loss: 0.6904 - accuracy: 0.52 - ETA: 1s - loss: 0.6894 - accuracy: 0.52 - ETA: 1s - loss: 0.6875 - accuracy: 0.52 - ETA: 1s - loss: 0.6846 - accuracy: 0.51 - ETA: 0s - loss: 0.6869 - accuracy: 0.51 - ETA: 0s - loss: 0.6869 - accuracy: 0.52 - ETA: 0s - loss: 0.6866 - accuracy: 0.52 - ETA: 0s - loss: 0.6864 - accuracy: 0.52 - ETA: 0s - loss: 0.6862 - accuracy: 0.52 - ETA: 0s - loss: 0.6864 - accuracy: 0.52 - 4s 5ms/sample - loss: 0.6858 - accuracy: 0.5257 - val_loss: 0.6851 - val_accuracy: 0.5100\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - ETA: 3s - loss: 0.7206 - accuracy: 0.43 - ETA: 3s - loss: 0.6880 - accuracy: 0.42 - ETA: 2s - loss: 0.6566 - accuracy: 0.46 - ETA: 2s - loss: 0.6545 - accuracy: 0.50 - ETA: 2s - loss: 0.6794 - accuracy: 0.51 - ETA: 2s - loss: 0.6795 - accuracy: 0.53 - ETA: 2s - loss: 0.6750 - accuracy: 0.54 - ETA: 2s - loss: 0.6734 - accuracy: 0.55 - ETA: 2s - loss: 0.6770 - accuracy: 0.53 - ETA: 1s - loss: 0.6762 - accuracy: 0.53 - ETA: 1s - loss: 0.6743 - accuracy: 0.53 - ETA: 1s - loss: 0.6753 - accuracy: 0.53 - ETA: 1s - loss: 0.6748 - accuracy: 0.53 - ETA: 1s - loss: 0.6724 - accuracy: 0.54 - ETA: 1s - loss: 0.6707 - accuracy: 0.54 - ETA: 0s - loss: 0.6698 - accuracy: 0.54 - ETA: 0s - loss: 0.6646 - accuracy: 0.55 - ETA: 0s - loss: 0.6650 - accuracy: 0.55 - ETA: 0s - loss: 0.6652 - accuracy: 0.55 - ETA: 0s - loss: 0.6655 - accuracy: 0.55 - ETA: 0s - loss: 0.6675 - accuracy: 0.55 - 4s 6ms/sample - loss: 0.6647 - accuracy: 0.5500 - val_loss: 0.6634 - val_accuracy: 0.6067\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - ETA: 3s - loss: 0.6339 - accuracy: 0.62 - ETA: 3s - loss: 0.5982 - accuracy: 0.62 - ETA: 2s - loss: 0.6307 - accuracy: 0.63 - ETA: 2s - loss: 0.6383 - accuracy: 0.59 - ETA: 2s - loss: 0.6228 - accuracy: 0.63 - ETA: 2s - loss: 0.6305 - accuracy: 0.62 - ETA: 2s - loss: 0.6186 - accuracy: 0.63 - ETA: 2s - loss: 0.6160 - accuracy: 0.64 - ETA: 2s - loss: 0.6394 - accuracy: 0.64 - ETA: 1s - loss: 0.6625 - accuracy: 0.64 - ETA: 1s - loss: 0.6585 - accuracy: 0.64 - ETA: 1s - loss: 0.6484 - accuracy: 0.65 - ETA: 1s - loss: 0.6501 - accuracy: 0.64 - ETA: 1s - loss: 0.6445 - accuracy: 0.65 - ETA: 1s - loss: 0.6449 - accuracy: 0.64 - ETA: 0s - loss: 0.6415 - accuracy: 0.64 - ETA: 0s - loss: 0.6552 - accuracy: 0.63 - ETA: 0s - loss: 0.6502 - accuracy: 0.63 - ETA: 0s - loss: 0.6522 - accuracy: 0.62 - ETA: 0s - loss: 0.6535 - accuracy: 0.61 - ETA: 0s - loss: 0.6548 - accuracy: 0.62 - 4s 5ms/sample - loss: 0.6555 - accuracy: 0.6214 - val_loss: 0.7654 - val_accuracy: 0.5233\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - ETA: 3s - loss: 0.8048 - accuracy: 0.50 - ETA: 3s - loss: 0.7280 - accuracy: 0.54 - ETA: 3s - loss: 0.7148 - accuracy: 0.54 - ETA: 2s - loss: 0.7011 - accuracy: 0.60 - ETA: 2s - loss: 0.6972 - accuracy: 0.58 - ETA: 2s - loss: 0.6926 - accuracy: 0.57 - ETA: 2s - loss: 0.6909 - accuracy: 0.56 - ETA: 2s - loss: 0.7005 - accuracy: 0.53 - ETA: 2s - loss: 0.6983 - accuracy: 0.55 - ETA: 1s - loss: 0.6922 - accuracy: 0.55 - ETA: 1s - loss: 0.6929 - accuracy: 0.55 - ETA: 1s - loss: 0.6908 - accuracy: 0.55 - ETA: 1s - loss: 0.6913 - accuracy: 0.56 - ETA: 1s - loss: 0.6925 - accuracy: 0.56 - ETA: 1s - loss: 0.6896 - accuracy: 0.56 - ETA: 0s - loss: 0.7064 - accuracy: 0.53 - ETA: 0s - loss: 0.7044 - accuracy: 0.54 - ETA: 0s - loss: 0.7026 - accuracy: 0.55 - ETA: 0s - loss: 0.7010 - accuracy: 0.56 - ETA: 0s - loss: 0.6996 - accuracy: 0.57 - ETA: 0s - loss: 0.6988 - accuracy: 0.56 - 4s 6ms/sample - loss: 0.6936 - accuracy: 0.5714 - val_loss: 0.6499 - val_accuracy: 0.5900\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - ETA: 4s - loss: 0.6444 - accuracy: 0.50 - ETA: 3s - loss: 0.6790 - accuracy: 0.51 - ETA: 3s - loss: 0.6546 - accuracy: 0.57 - ETA: 3s - loss: 0.6460 - accuracy: 0.56 - ETA: 3s - loss: 0.6535 - accuracy: 0.55 - ETA: 2s - loss: 0.6562 - accuracy: 0.56 - ETA: 2s - loss: 0.6700 - accuracy: 0.54 - ETA: 2s - loss: 0.6759 - accuracy: 0.54 - ETA: 2s - loss: 0.6701 - accuracy: 0.54 - ETA: 2s - loss: 0.6615 - accuracy: 0.55 - ETA: 1s - loss: 0.6553 - accuracy: 0.55 - ETA: 1s - loss: 0.6455 - accuracy: 0.58 - ETA: 1s - loss: 0.6429 - accuracy: 0.57 - ETA: 1s - loss: 0.6397 - accuracy: 0.58 - ETA: 1s - loss: 0.6423 - accuracy: 0.59 - ETA: 0s - loss: 0.6424 - accuracy: 0.58 - ETA: 0s - loss: 0.6412 - accuracy: 0.59 - ETA: 0s - loss: 0.6401 - accuracy: 0.59 - ETA: 0s - loss: 0.6391 - accuracy: 0.59 - ETA: 0s - loss: 0.6405 - accuracy: 0.58 - ETA: 0s - loss: 0.6399 - accuracy: 0.59 - 4s 6ms/sample - loss: 0.6383 - accuracy: 0.5900 - val_loss: 0.6601 - val_accuracy: 0.5633\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - ETA: 3s - loss: 0.5986 - accuracy: 0.59 - ETA: 3s - loss: 0.6066 - accuracy: 0.59 - ETA: 3s - loss: 0.5779 - accuracy: 0.63 - ETA: 2s - loss: 0.5823 - accuracy: 0.65 - ETA: 2s - loss: 0.6030 - accuracy: 0.65 - ETA: 2s - loss: 0.5950 - accuracy: 0.65 - ETA: 2s - loss: 0.6025 - accuracy: 0.64 - ETA: 2s - loss: 0.6136 - accuracy: 0.63 - ETA: 2s - loss: 0.6165 - accuracy: 0.63 - ETA: 1s - loss: 0.6139 - accuracy: 0.64 - ETA: 1s - loss: 0.6247 - accuracy: 0.63 - ETA: 1s - loss: 0.6344 - accuracy: 0.62 - ETA: 1s - loss: 0.6336 - accuracy: 0.62 - ETA: 1s - loss: 0.6310 - accuracy: 0.62 - ETA: 1s - loss: 0.6236 - accuracy: 0.64 - ETA: 0s - loss: 0.6239 - accuracy: 0.63 - ETA: 0s - loss: 0.6285 - accuracy: 0.62 - ETA: 0s - loss: 0.6234 - accuracy: 0.63 - ETA: 0s - loss: 0.6256 - accuracy: 0.62 - ETA: 0s - loss: 0.6258 - accuracy: 0.62 - ETA: 0s - loss: 0.6263 - accuracy: 0.62 - 4s 6ms/sample - loss: 0.6267 - accuracy: 0.6257 - val_loss: 0.6722 - val_accuracy: 0.5867\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - ETA: 3s - loss: 0.6206 - accuracy: 0.65 - ETA: 3s - loss: 0.5973 - accuracy: 0.64 - ETA: 3s - loss: 0.6041 - accuracy: 0.68 - ETA: 2s - loss: 0.6135 - accuracy: 0.65 - ETA: 2s - loss: 0.5993 - accuracy: 0.66 - ETA: 2s - loss: 0.5949 - accuracy: 0.65 - ETA: 2s - loss: 0.6069 - accuracy: 0.65 - ETA: 2s - loss: 0.5876 - accuracy: 0.67 - ETA: 2s - loss: 0.5762 - accuracy: 0.67 - ETA: 1s - loss: 0.5653 - accuracy: 0.68 - ETA: 1s - loss: 0.5600 - accuracy: 0.68 - ETA: 1s - loss: 0.5588 - accuracy: 0.68 - ETA: 1s - loss: 0.5658 - accuracy: 0.68 - ETA: 1s - loss: 0.5703 - accuracy: 0.67 - ETA: 1s - loss: 0.5661 - accuracy: 0.68 - ETA: 0s - loss: 0.5714 - accuracy: 0.67 - ETA: 0s - loss: 0.5778 - accuracy: 0.67 - ETA: 0s - loss: 0.5801 - accuracy: 0.66 - ETA: 0s - loss: 0.5809 - accuracy: 0.66 - ETA: 0s - loss: 0.5807 - accuracy: 0.67 - ETA: 0s - loss: 0.5828 - accuracy: 0.66 - 4s 6ms/sample - loss: 0.5846 - accuracy: 0.6657 - val_loss: 0.6405 - val_accuracy: 0.6100\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - ETA: 3s - loss: 0.5122 - accuracy: 0.78 - ETA: 3s - loss: 0.5741 - accuracy: 0.70 - ETA: 2s - loss: 0.5806 - accuracy: 0.64 - ETA: 2s - loss: 0.5762 - accuracy: 0.64 - ETA: 2s - loss: 0.5703 - accuracy: 0.65 - ETA: 2s - loss: 0.5559 - accuracy: 0.66 - ETA: 2s - loss: 0.5612 - accuracy: 0.67 - ETA: 2s - loss: 0.5606 - accuracy: 0.67 - ETA: 2s - loss: 0.5722 - accuracy: 0.64 - ETA: 1s - loss: 0.5770 - accuracy: 0.65 - ETA: 1s - loss: 0.5686 - accuracy: 0.65 - ETA: 1s - loss: 0.5756 - accuracy: 0.64 - ETA: 1s - loss: 0.5735 - accuracy: 0.64 - ETA: 1s - loss: 0.5775 - accuracy: 0.65 - ETA: 1s - loss: 0.5812 - accuracy: 0.65 - ETA: 0s - loss: 0.5792 - accuracy: 0.66 - ETA: 0s - loss: 0.5770 - accuracy: 0.66 - ETA: 0s - loss: 0.5723 - accuracy: 0.67 - ETA: 0s - loss: 0.5740 - accuracy: 0.66 - ETA: 0s - loss: 0.5763 - accuracy: 0.66 - ETA: 0s - loss: 0.5792 - accuracy: 0.65 - 4s 5ms/sample - loss: 0.5781 - accuracy: 0.6586 - val_loss: 0.7313 - val_accuracy: 0.5833\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - ETA: 3s - loss: 0.5347 - accuracy: 0.71 - ETA: 3s - loss: 0.6010 - accuracy: 0.68 - ETA: 3s - loss: 0.5974 - accuracy: 0.67 - ETA: 2s - loss: 0.5728 - accuracy: 0.69 - ETA: 2s - loss: 0.5561 - accuracy: 0.69 - ETA: 2s - loss: 0.5770 - accuracy: 0.67 - ETA: 2s - loss: 0.5916 - accuracy: 0.65 - ETA: 2s - loss: 0.6015 - accuracy: 0.64 - ETA: 2s - loss: 0.5948 - accuracy: 0.64 - ETA: 1s - loss: 0.5888 - accuracy: 0.65 - ETA: 1s - loss: 0.5909 - accuracy: 0.64 - ETA: 1s - loss: 0.5897 - accuracy: 0.65 - ETA: 1s - loss: 0.5860 - accuracy: 0.65 - ETA: 1s - loss: 0.5785 - accuracy: 0.65 - ETA: 1s - loss: 0.5796 - accuracy: 0.66 - ETA: 0s - loss: 0.5781 - accuracy: 0.66 - ETA: 0s - loss: 0.5729 - accuracy: 0.66 - ETA: 0s - loss: 0.5752 - accuracy: 0.66 - ETA: 0s - loss: 0.5734 - accuracy: 0.66 - ETA: 0s - loss: 0.5810 - accuracy: 0.65 - ETA: 0s - loss: 0.5821 - accuracy: 0.65 - 4s 6ms/sample - loss: 0.5797 - accuracy: 0.6571 - val_loss: 0.6458 - val_accuracy: 0.6300\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.96 - ETA: 0s - loss: 0.6452 - accuracy: 0.90 - ETA: 0s - loss: 0.6796 - accuracy: 0.85 - ETA: 0s - loss: 0.6658 - accuracy: 0.71 - ETA: 0s - loss: 0.6514 - accuracy: 0.63 - 0s 1ms/sample - loss: 0.6458 - accuracy: 0.6300\n",
      "0.6458389655749003 0.63\n"
     ]
    }
   ],
   "source": [
    "#RNN LSTM\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(500)),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "    \n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_sig,train_lab, epochs=10,\n",
    "                    validation_data=(test_sig,test_lab))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_sig,test_lab)\n",
    "\n",
    "print(test_loss,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 1, 697)\n",
      "(300, 1, 697)\n",
      "Train on 700 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - ETA: 8s - loss: 0.7004 - accuracy: 0.46 - 0s 665us/sample - loss: 0.6952 - accuracy: 0.4857\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.50 - 0s 63us/sample - loss: 0.6934 - accuracy: 0.5171\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.62 - 0s 63us/sample - loss: 0.6972 - accuracy: 0.4900\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.7089 - accuracy: 0.40 - 0s 63us/sample - loss: 0.6954 - accuracy: 0.4843\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.53 - 0s 76us/sample - loss: 0.6944 - accuracy: 0.4914\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.50 - 0s 64us/sample - loss: 0.6939 - accuracy: 0.4886\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - 0s 61us/sample - loss: 0.6941 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.68 - 0s 70us/sample - loss: 0.6933 - accuracy: 0.5086\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.46 - 0s 63us/sample - loss: 0.6950 - accuracy: 0.4929\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.43 - 0s 66us/sample - loss: 0.6946 - accuracy: 0.4871\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#change length of signals into the longest one, many zeros in the tail of signals\n",
    "train = pd.read_csv(\"D:\\\\APE\\\\ml_model\\\\train_data.csv\",header=None)\n",
    "train_label = to_categorical(np.array(train.iloc[:,0]))\n",
    "train_signal = np.array(train.iloc[:,1:])\n",
    "train_signal = train_signal.reshape(700,1,697)\n",
    "\n",
    "test = pd.read_csv(\"D:\\\\APE\\\\ml_model\\\\test_data.csv\",header=None)\n",
    "test_label = to_categorical(np.array(test.iloc[:,0]))\n",
    "test_signal = np.array(test.iloc[:,1:])\n",
    "test_signal = test_signal.reshape(300,1,697)\n",
    "\n",
    "\n",
    "print(train_signal.shape)\n",
    "print(test_signal.shape)\n",
    "\n",
    "#1D CNN\n",
    "n_timesteps, n_features, n_outputs = train_signal.shape[1], train_signal.shape[2], train_label.shape[1]\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(filters=1, kernel_size=1, activation='tanh', input_shape=(n_timesteps,n_features)))\n",
    "model.add(tf.keras.layers.Conv1D(filters=1, kernel_size=1, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=1))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(100, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(n_outputs,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_signal, train_label, epochs=10)\n",
    "_, accuracy = model.evaluate(test_signal, test_label, verbose=0)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
